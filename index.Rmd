---
title: "科技文献可视化期末作业"
author: 张杨燚 2019101458，彭子健 2019101455
output: 
  html_document: 
    df_print: default
    highlight: kate
    keep_md: yes
    theme: paper
    toc: yes
editor_options: 
  chunk_output_type: inline
---


# Note
**整个项目都放到了github上： https://github.com/pzjzeason/bib 。**在统计论文平均每年被引以及关键词突发检测这两个任务中，用到的是python的代码，python代码见`py.ipynb`(运行需要jupyter环境，或者直接在github仓库中查看)。

# 1 文献检索
**数据源**: Clarivate Analytics Web of Science (http://apps.webofknowledge.com)，选择“核心数据库”


**检索式**: （标题）TI = ( smart factory OR intelligent factory OR ubiquitous factory OR real-time factory OR smart factories OR smarter factories OR intelligent factories OR ubiquitous factories OR real-time factories OR smart manufacturing OR smarter manufacturing OR intelligent manufacturing OR ubiquitous manufacturing OR real-time manufacturing OR factory-of-things)) AND 语种: (English)

**时间区间**: 2007年-2016年5月（手动排除5月份之后的数据）

**文章类型**: 会议和论文

**检索日期**: 2019年11月29日

**导出格式**: Bibtex格式


# 2 导入数据并转换
```{r echo = T, results = 'hide', message=F, warning=F}
# 导入包
library(bibliometrix)
library(igraph)
library(knitr)
library(kableExtra)
library(data.table)

D <- readFiles('07-16.bib')
M <- convert2df(D, dbsource='isi', format='bibtex') # 利用convert2df转化
```


# 3 Citation Network Analysis

## 3.1 Overall Citation Network
```{r echo = T, results = 'hide',  message=F, warning=F}
# 文献互引网络
## function that reverses all edges in graph
graph.reverse <- function (graph) {
  if (!is.directed(graph))
    return(graph)
  e <- get.data.frame(graph, what="edges")
  ## swap "from" & "to"
  neworder <- 1:length(e)
  neworder[1:2] <- c(2,1)
  e <- e[neworder]
  names(e) <- names(e)[neworder]
  graph.data.frame(e, vertices = get.data.frame(graph, what="vertices"))
}

## use histNetwork in bibliometrix to compute citation
histResults  <- histNetwork(M, min.citations = 0,sep = ";")
citationGraph <- graph.reverse(graph_from_adjacency_matrix(histResults$NetMatrix, mode="directed", weighted=NULL, diag= FALSE))
splitNames=strsplit(names(V(citationGraph)),",")       
nameAndYear=lapply(splitNames,
  function(l){
    l=l[1:2]
    l=paste(strsplit(l[1],' ')[[1]][1],'(',l[2],')', sep='')
})
V(citationGraph)$lab <- tolower(unlist(nameAndYear))

## plot
plot.igraph(citationGraph,
            vertex.label=NA,  
            vertex.color= "green",  
            vertex.size=3, 
            vertex.label.cex=0.8, 
            edge.color="red", 
            edge.arrow.size=0.3,
            edge.arrow.width=1, 
            layout=layout_randomly,
            main="Citation Network Analysis")
```

## 3.2 Top 3 biggest connected components
```{r}
singlePoints = which(degree(citationGraph)==0)    
connectGraph = delete.vertices(citationGraph, singlePoints)  
cps = components(connectGraph,mode='weak')
plotCompoent = function(index) {
    rankstr = c('First','Second', 'Third')
    cluster = which(cps$csize == sort(cps$csize, decreasing = TRUE)[index])
    g = induced_subgraph(citationGraph,
                     vids=names(cps$membership)[which(cps$membership==cluster)]
                     )
    plot.igraph(g,  
            vertex.label = V(g)$lab,
            vertex.color= "green",  
            vertex.size=3, 
            vertex.label.cex=0.8, 
            edge.color="black", 
            edge.arrow.size=0.3,
            edge.arrow.width=1, 
            layout=layout.fruchterman.reingold,
            main=paste(rankstr[index], "biggest connected component of the citation network"))
}

# first
plotCompoent(1)

# second 
plotCompoent(2)

# third
plotCompoent(3)
```

# 4 全局/局部被引分析
```{r echo = T, results = 'hide',  message=F, warning=F}
# 被引统计
citationCount <- localCitations(M, sep=';')$Papers
dt1 <- data.table(citationCount, key = "Paper") 
dt2 <- data.table(M, key = "SR")
citationCountMerge <- dt1[dt2][,c('TI','AU','SO','Year','GCS', 'LCS')]
colnames(citationCountMerge) <- c('Title', 'Author', 'Journal', 'Year', 'GCS', 'LCS')
```

## 4.1 局部被引top 10
```{r}
# 局部被引top10
LCS_top_10 = data.frame(
    Rank=c(1:10), 
    citationCountMerge[order(citationCountMerge$LCS,decreasing = TRUE),][c(1:10),],
    row.names=NULL
)
kable(LCS_top_10,caption = "LCS Top 10")%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)
```

## 4.2 全局被引被引top 10
```{r}
# 全局被引被引top10
GCS_top_10 = data.frame(
    Rank=c(1:10), 
    citationCountMerge[order(citationCountMerge$GCS,decreasing = TRUE),][c(1:10),],
    row.names=NULL
)
kable(GCS_top_10,caption = "GCS Top 10") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)
```


## 4.3 GCS Top 10: citation forward every year from WOS
```{r}
citedPerYear = read.csv('./cited-forward.csv', check.names=FALSE)
kable(head(citedPerYear, 10),caption = "Citation forward every year") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)
```

# 5 作者关键词网络分析
```{r}
# 构建关键词共现网络
coOccNet <- biblioNetwork(M, analysis = "co-occurrences", network = "author_keywords", sep = ";")
# 绘图
net = networkPlot(coOccNet, normalize="inclusion", weighted=T, n = 16, Title = "Keyword Co-occurrences", type = "fruchterman", size= 14, size.cex= T, edgesize = 6,labelsize=0.8, remove.isolates = TRUE, alpha = 0.8)
```

# 6 burst detection 
这部分比较难，涉及了Kleinberg’s Burst算法，我们对此并不熟悉。于是找了实现这个算法的R包`burst`，但是文档说明不够清晰，并且这个实现版本适于连续型数值，而关键词的时间点是以年为单位。这部分我们做了一下的工作：
1. 按照论文的方式，检索1995～2016符合检索式的文献共1141篇，导出bibtex格式
2. 统计每年出现的关键词
3. 对关键词做stemming操作，并计算其频数
4. 尝试用python的burst_detection包进行关键词的burst detection

## 6.1 关键词统计结果
关键词stem后按年计数的完整结果请查看`stem-keywords-by-year.json`,每一年的top20关键词及其频数结果在`keywords-freq-top20.csv`。论文图-8中的关键词的每年频数在`keywords-freq.csv`。
这里我们`keywords-freq-top20.csv`和`selected-keywords-freq.csv`打印出来：
```{r}
top20 = read.csv('./keywords-freq-top20.csv', check.names=FALSE)
kable(top20,caption = "Top20 keywords frequency every year(1995~2016), scroll to see more") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F) %>%
  scroll_box(width = "100%", height = "fit-content")
kable(read.csv('./selected-keywords-freq.csv'),caption = "Author selected keywords frequency every year") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)
```

结合每年的关键词词频和作者选择的关键词每年出现频数，可以观察到，作者挑选的词是较为主观的，大部分词出现的频数都非常低，在当年的关键词频数中的排名都非常靠后，例如function。部分词的涌现时间也存在误差，例如base。

## 6.2 burst detection python实现结果
burst detection的结果如下：
```{r}
kable(read.csv('./burst-result.csv'),caption = "burst detection result of python implement") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
```

Python代码参见`py.ipynb`的2.5节。有一些关键词没有监测到burst，可能是这个第三方包实现上存在问题，或者是还有更优参数。有一些结果是比较吻合，例如：rfid我们的结果是2009～2013，作者的结果是2008-2012；artifici的结果跟作者一致，都是1996～1998; expert、neural、wireless、monitor也都比较接近。